{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_result\n",
      "Pass           12361\n",
      "Withdrawn      10156\n",
      "Fail            7052\n",
      "Distinction     3024\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from time import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import featuretools as ft\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "load_dotenv()\n",
    "column_names = os.getenv('COLUMN_NAMES').split(',')\n",
    "dummies_col_names = os.getenv('DUMMIES_COL_NAMES').split(',')\n",
    "categorical_col_names = os.getenv('CATEGORICAL_COLUMN_NAMES').split(',')\n",
    "\n",
    "\n",
    "df = pd.read_csv('studentinfo.csv')\n",
    "df = df.drop(['id_student'], axis=1)\n",
    "\n",
    "class_counts = df['final_result'].value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA.ENCODER()\n",
    "# Open the JSON file\n",
    "with open('encoding.json', 'r') as f:\n",
    "        # Load the JSON file into a dictionary\n",
    "        mappings = json.load(f)\n",
    "\n",
    "# Replace NaN values with 'Unknown'\n",
    "for column_name in column_names:\n",
    "        if column_name in categorical_col_names:\n",
    "            df[column_name] = df[column_name].fillna(\"Unknown\")\n",
    "\n",
    "# Replace values in each column based on the mappings\n",
    "for column, mapping in mappings.items():\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE_RANDOMFOREST_MODEL()\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \"\"\"\n",
    "    Perform feature engineering on the given DataFrame.\n",
    "    Adds new features by combining existing features.\n",
    "\n",
    "    <Feature: num_of_prev_attempts + studied_credits>, \n",
    "    <Feature: num_of_prev_attempts / studied_credits>, \n",
    "    <Feature: studied_credits / num_of_prev_attempts>, \n",
    "    <Feature: num_of_prev_attempts * studied_credits>, \n",
    "    <Feature: num_of_prev_attempts - studied_credits>,\n",
    "    <Feature: num_of_prev_attempts ^ 2>,\n",
    "    <Feature: studied_credits ^ 2>,\n",
    "    <Feature: num_of_prev_attempts ^ 3>,\n",
    "    <Feature: studied_credits ^ 3>,\n",
    "    <Feature: log(num_of_prev_attempts)>,\n",
    "    <Feature: log(studied_credits)>\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to perform feature engineering on.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The DataFrame with the new features added.\n",
    "    \"\"\"\n",
    "    #Feature: num_of_prev_attempts + studied_credits\n",
    "    df['num_of_prev_attempts + studied_credits'] = df['num_of_prev_attempts'] + df['studied_credits']\n",
    "\n",
    "    #Feature: num_of_prev_attempts / studied_credits\n",
    "    df['num_of_prev_attempts / studied_credits'] = np.where(df['studied_credits'] == 0, 0, df['num_of_prev_attempts'] / df['studied_credits'])\n",
    "\n",
    "    #Feature: studied_credits / num_of_prev_attempts\n",
    "    df['studied_credits / num_of_prev_attempts'] = np.where(df['num_of_prev_attempts'] == 0, 0, df['studied_credits'] / df['num_of_prev_attempts'])\n",
    "\n",
    "    #Feature: num_of_prev_attempts * studied_credits\n",
    "    df['num_of_prev_attempts * studied_credits'] = df['num_of_prev_attempts'] * df['studied_credits']\n",
    "\n",
    "    #Feature: num_of_prev_attempts - studied_credits\n",
    "    df['num_of_prev_attempts - studied_credits'] = df['num_of_prev_attempts'] - df['studied_credits']\n",
    "\n",
    "    #Feature: num_of_prev_attempts ^ 2\n",
    "    df['num_of_prev_attempts ^ 2'] = df['num_of_prev_attempts'] ** 2\n",
    "\n",
    "    #Feature: studied_credits ^ 2\n",
    "    df['studied_credits ^ 2'] = df['studied_credits'] ** 2\n",
    "\n",
    "    #Feature: num_of_prev_attempts ^ 3\n",
    "    df['num_of_prev_attempts ^ 3'] = df['num_of_prev_attempts'] ** 3\n",
    "\n",
    "    #Feature: studied_credits ^ 3\n",
    "    df['studied_credits ^ 3'] = df['studied_credits'] ** 3\n",
    "\n",
    "    #Feature: log(num_of_prev_attempts)\n",
    "    df['log(num_of_prev_attempts)'] = df['num_of_prev_attempts'].apply(lambda x: 0 if x == 0 else math.log(x))\n",
    "\n",
    "    #Feature: log(studied_credits)\n",
    "    df['log(studied_credits)'] = df['studied_credits'].apply(lambda x: 0 if x == 0 else math.log(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-Dataset Head:\n",
      "   code_module  code_presentation  gender  region  highest_education  \\\n",
      "0            1                  2       1       2                  4   \n",
      "1            1                  2       2       1                  4   \n",
      "2            1                  2       2      15                  3   \n",
      "\n",
      "   imd_band  age_band  num_of_prev_attempts  studied_credits  disability  \\\n",
      "0        10         3                     0              240           1   \n",
      "1         3         2                     0               60           1   \n",
      "2         4         2                     0               60           2   \n",
      "\n",
      "   final_result  \n",
      "0             1  \n",
      "1             1  \n",
      "2             0  \n",
      "\n",
      "1/11-target droped from dataset\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_MODEL()\n",
    "\n",
    "time_start = time()\n",
    "print(\"0-Dataset Head:\")\n",
    "print(df.head(3))\n",
    "print()\n",
    "\n",
    "# Split the dataset into features and target\n",
    "# X has features minus the target column\n",
    "X = df.drop(['final_result'], axis=1)\n",
    "print(\"1/11-target droped from dataset\")\n",
    "\n",
    "if False:\n",
    "    # Feature Engineering\n",
    "    print(\"X columns: \", X.columns)\n",
    "    print(\"X head: \", X.head(3))\n",
    "    X = feature_engineering(X)\n",
    "    print(\"1.5-Feature Engineering applied to dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_oneHotEncoder_and_encode()\n",
    "\n",
    "def create_oneHotEncoder_and_encode(df):\n",
    "    \"\"\"\n",
    "    Create a OneHotEncoder and fit it to the given DataFrame and encode the DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to fit the encoder to and to encode.\n",
    "    \n",
    "    Returns:\n",
    "    df_encoded (pandas.DataFrame): The DataFrame with the categorical columns encoded.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a OneHotEncoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Fit the encoder using the larger dataset\n",
    "    encoder.fit(df[categorical_col_names])\n",
    "\n",
    "    # Save the encoder to a file\n",
    "    dump(encoder, 'OneHotEncoder.joblib')\n",
    "\n",
    "    # Transform the DataFrame and convert the sparse matrix to a dense array\n",
    "    df_encoded = pd.DataFrame(encoder.transform(df[categorical_col_names]).toarray())\n",
    "\n",
    "    # Convert the data type of the columns to int (ou bool?)\n",
    "    df_encoded = df_encoded.astype(bool)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/11-encoder created and encode applied to dataset\n",
      "\n",
      "Class counts: \n",
      "final_result\n",
      "0    17208\n",
      "1    15385\n",
      "Name: count, dtype: int64\n",
      "\n",
      "3/11-target column extracted from dataset into y\n",
      "4/11-dataset split into training and testing sets\n",
      "\n",
      "Head of X_train:\n",
      "         0      1      2      3      4      5      6      7      8      9   \\\n",
      "1949  False   True  False  False  False  False  False   True  False  False   \n",
      "9647  False  False   True  False  False  False  False  False  False   True   \n",
      "\n",
      "      ...     37     38     39     40     41     42     43     44    45     46  \n",
      "1949  ...  False  False  False  False  False  False   True  False  True  False  \n",
      "9647  ...  False  False  False  False  False   True  False  False  True  False  \n",
      "\n",
      "[2 rows x 47 columns]\n",
      "\n",
      "Head of y_train:\n",
      "1949    1\n",
      "9647    0\n",
      "Name: final_result, dtype: int64\n",
      "\n",
      "5/11-model trained\n",
      "6/11-model prediction completed\n",
      "\n",
      "Cross-validated scores: [0.51833103 0.54272128 0.44930204 0.45612151 0.49677815]\n",
      "\n",
      "Previous score: 0.53\n",
      "Current F1 Score:  0.5467015022860875\n",
      "\n",
      "Time to fit: 0.09035339752833048 minutes\n",
      "Time elapsed: 0.5135368585586548 minutes\n",
      "-train_model finished\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_MODEL() CONTINUES\n",
    "\n",
    "X = create_oneHotEncoder_and_encode(X)\n",
    "print(\"2/11-encoder created and encode applied to dataset\")\n",
    "\n",
    "class_counts = df['final_result'].value_counts()\n",
    "print()\n",
    "print(\"Class counts: \")\n",
    "print(class_counts)\n",
    "print()\n",
    "\n",
    "# y has the target column and is converted to binary\n",
    "y = df['final_result']\n",
    "print(\"3/11-target column extracted from dataset into y\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"4/11-dataset split into training and testing sets\")\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "\"\"\" sm = SMOTE()\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "print(\"4.1-SMOTE applied to training data\") \"\"\"\n",
    "\n",
    "print()\n",
    "print(\"Head of X_train:\")\n",
    "print(X_train.head(2))\n",
    "print()\n",
    "#print(\"X Dtypes\")\n",
    "#print(X_train.dtypes)\n",
    "#print()\n",
    "print(\"Head of y_train:\")\n",
    "print(y_train.head(2))\n",
    "print()\n",
    "#print(\"Y Dtypes\")\n",
    "#print(y_train.dtypes)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(X_train, y_train)\n",
    "print(\"5/11-model trained\")\n",
    "time_fit = time()\n",
    "\n",
    "# Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"6/11-model prediction completed\")\n",
    "\n",
    "# Save the model\n",
    "#database.update_model_file(database_name, model_id, model)\n",
    "#print(\"7/11-model file updated\")\n",
    "\n",
    "# Store the evaluation in the database\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "#database.store_evaluation(database_name, model_id, matrix)\n",
    "#print(\"8/11-evaluation stored in database\")\n",
    "\n",
    "# set model atribute is_trained to true\n",
    "#database.set_model_trained(database_name, model_id)\n",
    "#print(\"9/11-model trained set to true\")\n",
    "\n",
    "#if database.set_ds_train_id(database_name=database_name, model_id=model_id, ds_id=ds_id):\n",
    "    #print(\"10/11-dataset train id set\")\n",
    "        \n",
    "# Predict the probabilities for the test dataset\n",
    "\"\"\" y_score = model.predict_proba(X_test)[:, 1]\n",
    "vz.create_ROC(model_id, y_test, y_score)\n",
    "vz.create_confusion_matrix(database_name, model_id)\n",
    "vz.create_PRC(model_id, y_test, y_score)\n",
    "print(\"11/11-visualizations created\") \"\"\"\n",
    "\n",
    "# print f1 score\n",
    "tn, fp, fn, tp = matrix.ravel()\n",
    "    \n",
    "# Convert numpy.int64 types to int\n",
    "fp, fn, tp, tn = int(fp), int(fn), int(tp), int(tn)\n",
    "\n",
    "precision = tp / float(tp + fp)\n",
    "recall = tp / float(tp + fn)\n",
    "f1 = 2 * (precision * recall) / float(precision + recall)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print()\n",
    "print(\"Cross-validated scores:\", scores)\n",
    "\n",
    "print()\n",
    "print(\"Previous score: 0.53\")\n",
    "print(\"Current F1 Score: \", f1)\n",
    "print()\n",
    "\n",
    "time_end = time()\n",
    "print(f\"Time to fit: {(time_fit - time_start) / 60} minutes\")\n",
    "print(f\"Time elapsed: {(time_end - time_start) / 60} minutes\")\n",
    "print(\"-train_model finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
